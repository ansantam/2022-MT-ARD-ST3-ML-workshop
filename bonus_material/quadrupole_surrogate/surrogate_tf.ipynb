{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cheetah\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmsk-ipc\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jankaiser/Documents/DESY/quadrupole-surrogate/wandb/run-20220329_151117-3rnl3zfx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msk-ipc/quadrupole-surrogate/runs/3rnl3zfx\" target=\"_blank\">logical-sponge-1</a></strong> to <a href=\"https://wandb.ai/msk-ipc/quadrupole-surrogate\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/msk-ipc/quadrupole-surrogate/runs/3rnl3zfx?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff0b2b90130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"quadrupole-surrogate-pytorch\",\n",
    "    entity=\"msk-ipc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate input dataset\n",
    "Each sample is array of beam parameters, k1 and length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_keys = ['energy','mu_x','mu_xp','mu_y','mu_yp','sigma_p','sigma_s','sigma_x','sigma_xp','sigma_y','sigma_yp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{\n",
    "    \"mu_x\": np.random.uniform(-1e-3, 1e-3),\n",
    "    \"mu_y\": np.random.uniform(-1e-3, 1e-3),\n",
    "    \"mu_xp\": np.random.uniform(-1e-4, 1e-4),\n",
    "    \"mu_yp\": np.random.uniform(-1e-4, 1e-4),\n",
    "    \"sigma_x\": np.random.uniform(1e-5, 5e-4),\n",
    "    \"sigma_y\": np.random.uniform(1e-5, 5e-4),\n",
    "    \"sigma_xp\": np.random.uniform(1e-6, 5e-5),\n",
    "    \"sigma_yp\": np.random.uniform(1e-6, 5e-5),\n",
    "    \"sigma_s\": np.random.uniform(1e-6, 5e-5),\n",
    "    \"sigma_p\": np.random.uniform(1e-4, 1e-3),\n",
    "    \"energy\": np.random.uniform(80e6, 160e6)\n",
    "} for _ in range(n)]\n",
    "\n",
    "beams = [cheetah.ParameterBeam.from_parameters(**p) for p in parameters]\n",
    "\n",
    "X1 = np.array([[b.parameters[k] for k in parameter_keys] for b in beams])\n",
    "\n",
    "X0 = np.array([[np.random.uniform(0.1, 0.3), np.random.uniform(-15.0, 15.0)] for _ in range(n)])\n",
    "\n",
    "X = np.hstack([X0, X1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate \"label\" dataset\n",
    "Each sample is beam paramters of outgoing beam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for incoming, x in zip(beams, X0):\n",
    "    quadrupole = cheetah.Quadrupole(length=x[0], k1=x[1])\n",
    "    outgoing = quadrupole(incoming)\n",
    "    y.append(outgoing)\n",
    "\n",
    "y = np.array([[b.parameters[k] for k in parameter_keys] for b in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ANN\n",
    "Not comment needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation\n",
    "X_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:11:58.398149: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(11)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36251077, -0.00973265, -0.05018152, -0.20854494,  0.45580605,\n",
       "         0.01306107,  0.4522051 , -0.24409851, -0.22434995, -0.6310982 ,\n",
       "         0.23470964]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just test that it doesn't crash\n",
    "# Make list of length 1 because Keras expects batch of multiple inputs\n",
    "model.predict(X_train_scaled[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "55/55 [==============================] - 2s 19ms/step - loss: 0.9495 - mae: 0.7862 - val_loss: 0.8356 - val_mae: 0.7282 - _timestamp: 1648559532.0000 - _runtime: 54.0000\n",
      "Epoch 2/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.6961 - mae: 0.6529 - val_loss: 0.5914 - val_mae: 0.5879 - _timestamp: 1648559534.0000 - _runtime: 56.0000\n",
      "Epoch 3/200\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.4825 - mae: 0.5170 - val_loss: 0.4134 - val_mae: 0.4642 - _timestamp: 1648559535.0000 - _runtime: 57.0000\n",
      "Epoch 4/200\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.3572 - mae: 0.4261 - val_loss: 0.3303 - val_mae: 0.4046 - _timestamp: 1648559536.0000 - _runtime: 58.0000\n",
      "Epoch 5/200\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.2955 - mae: 0.3808 - val_loss: 0.2753 - val_mae: 0.3654 - _timestamp: 1648559537.0000 - _runtime: 59.0000\n",
      "Epoch 6/200\n",
      "55/55 [==============================] - 2s 25ms/step - loss: 0.2448 - mae: 0.3442 - val_loss: 0.2250 - val_mae: 0.3296 - _timestamp: 1648559539.0000 - _runtime: 61.0000\n",
      "Epoch 7/200\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.1986 - mae: 0.3102 - val_loss: 0.1822 - val_mae: 0.2967 - _timestamp: 1648559540.0000 - _runtime: 62.0000\n",
      "Epoch 8/200\n",
      "55/55 [==============================] - 1s 23ms/step - loss: 0.1617 - mae: 0.2810 - val_loss: 0.1498 - val_mae: 0.2714 - _timestamp: 1648559541.0000 - _runtime: 63.0000\n",
      "Epoch 9/200\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.1336 - mae: 0.2574 - val_loss: 0.1275 - val_mae: 0.2505 - _timestamp: 1648559542.0000 - _runtime: 64.0000\n",
      "Epoch 10/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.1137 - mae: 0.2385 - val_loss: 0.1102 - val_mae: 0.2343 - _timestamp: 1648559543.0000 - _runtime: 65.0000\n",
      "Epoch 11/200\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.0993 - mae: 0.2236 - val_loss: 0.0989 - val_mae: 0.2232 - _timestamp: 1648559543.0000 - _runtime: 65.0000\n",
      "Epoch 12/200\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0895 - mae: 0.2126 - val_loss: 0.0897 - val_mae: 0.2129 - _timestamp: 1648559544.0000 - _runtime: 66.0000\n",
      "Epoch 13/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0826 - mae: 0.2043 - val_loss: 0.0847 - val_mae: 0.2076 - _timestamp: 1648559545.0000 - _runtime: 67.0000\n",
      "Epoch 14/200\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0770 - mae: 0.1975 - val_loss: 0.0783 - val_mae: 0.1987 - _timestamp: 1648559546.0000 - _runtime: 68.0000\n",
      "Epoch 15/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0724 - mae: 0.1913 - val_loss: 0.0741 - val_mae: 0.1930 - _timestamp: 1648559547.0000 - _runtime: 69.0000\n",
      "Epoch 16/200\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.0684 - mae: 0.1855 - val_loss: 0.0704 - val_mae: 0.1875 - _timestamp: 1648559548.0000 - _runtime: 70.0000\n",
      "Epoch 17/200\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.0651 - mae: 0.1807 - val_loss: 0.0670 - val_mae: 0.1824 - _timestamp: 1648559549.0000 - _runtime: 71.0000\n",
      "Epoch 18/200\n",
      "55/55 [==============================] - 2s 31ms/step - loss: 0.0621 - mae: 0.1762 - val_loss: 0.0643 - val_mae: 0.1791 - _timestamp: 1648559551.0000 - _runtime: 73.0000\n",
      "Epoch 19/200\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0593 - mae: 0.1722 - val_loss: 0.0617 - val_mae: 0.1752 - _timestamp: 1648559552.0000 - _runtime: 74.0000\n",
      "Epoch 20/200\n",
      "55/55 [==============================] - 1s 25ms/step - loss: 0.0570 - mae: 0.1689 - val_loss: 0.0592 - val_mae: 0.1715 - _timestamp: 1648559553.0000 - _runtime: 75.0000\n",
      "Epoch 21/200\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0547 - mae: 0.1653 - val_loss: 0.0564 - val_mae: 0.1675 - _timestamp: 1648559554.0000 - _runtime: 76.0000\n",
      "Epoch 22/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0527 - mae: 0.1625 - val_loss: 0.0546 - val_mae: 0.1643 - _timestamp: 1648559555.0000 - _runtime: 77.0000\n",
      "Epoch 23/200\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.0507 - mae: 0.1589 - val_loss: 0.0529 - val_mae: 0.1623 - _timestamp: 1648559556.0000 - _runtime: 78.0000\n",
      "Epoch 24/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0489 - mae: 0.1563 - val_loss: 0.0510 - val_mae: 0.1590 - _timestamp: 1648559557.0000 - _runtime: 79.0000\n",
      "Epoch 25/200\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.0473 - mae: 0.1536 - val_loss: 0.0490 - val_mae: 0.1558 - _timestamp: 1648559558.0000 - _runtime: 80.0000\n",
      "Epoch 26/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0456 - mae: 0.1509 - val_loss: 0.0477 - val_mae: 0.1536 - _timestamp: 1648559559.0000 - _runtime: 81.0000\n",
      "Epoch 27/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0442 - mae: 0.1487 - val_loss: 0.0464 - val_mae: 0.1521 - _timestamp: 1648559559.0000 - _runtime: 81.0000\n",
      "Epoch 28/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0429 - mae: 0.1466 - val_loss: 0.0447 - val_mae: 0.1491 - _timestamp: 1648559560.0000 - _runtime: 82.0000\n",
      "Epoch 29/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0415 - mae: 0.1442 - val_loss: 0.0435 - val_mae: 0.1472 - _timestamp: 1648559561.0000 - _runtime: 83.0000\n",
      "Epoch 30/200\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.0402 - mae: 0.1420 - val_loss: 0.0421 - val_mae: 0.1451 - _timestamp: 1648559562.0000 - _runtime: 84.0000\n",
      "Epoch 31/200\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0391 - mae: 0.1402 - val_loss: 0.0408 - val_mae: 0.1429 - _timestamp: 1648559563.0000 - _runtime: 85.0000\n",
      "Epoch 32/200\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0379 - mae: 0.1381 - val_loss: 0.0397 - val_mae: 0.1408 - _timestamp: 1648559564.0000 - _runtime: 86.0000\n",
      "Epoch 33/200\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0368 - mae: 0.1361 - val_loss: 0.0386 - val_mae: 0.1397 - _timestamp: 1648559565.0000 - _runtime: 87.0000\n",
      "Epoch 34/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0357 - mae: 0.1345 - val_loss: 0.0376 - val_mae: 0.1383 - _timestamp: 1648559566.0000 - _runtime: 88.0000\n",
      "Epoch 35/200\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0344 - mae: 0.1324 - val_loss: 0.0357 - val_mae: 0.1345 - _timestamp: 1648559567.0000 - _runtime: 89.0000\n",
      "Epoch 36/200\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.0334 - mae: 0.1301 - val_loss: 0.0350 - val_mae: 0.1336 - _timestamp: 1648559568.0000 - _runtime: 90.0000\n",
      "Epoch 37/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0325 - mae: 0.1289 - val_loss: 0.0340 - val_mae: 0.1320 - _timestamp: 1648559568.0000 - _runtime: 90.0000\n",
      "Epoch 38/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0316 - mae: 0.1271 - val_loss: 0.0332 - val_mae: 0.1310 - _timestamp: 1648559569.0000 - _runtime: 91.0000\n",
      "Epoch 39/200\n",
      "55/55 [==============================] - 1s 25ms/step - loss: 0.0307 - mae: 0.1253 - val_loss: 0.0321 - val_mae: 0.1284 - _timestamp: 1648559571.0000 - _runtime: 93.0000\n",
      "Epoch 40/200\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.0298 - mae: 0.1237 - val_loss: 0.0317 - val_mae: 0.1274 - _timestamp: 1648559572.0000 - _runtime: 94.0000\n",
      "Epoch 41/200\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0292 - mae: 0.1225 - val_loss: 0.0302 - val_mae: 0.1247 - _timestamp: 1648559573.0000 - _runtime: 95.0000\n",
      "Epoch 42/200\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0284 - mae: 0.1208 - val_loss: 0.0297 - val_mae: 0.1235 - _timestamp: 1648559573.0000 - _runtime: 95.0000\n",
      "Epoch 43/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0275 - mae: 0.1189 - val_loss: 0.0290 - val_mae: 0.1232 - _timestamp: 1648559574.0000 - _runtime: 96.0000\n",
      "Epoch 44/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0269 - mae: 0.1177 - val_loss: 0.0283 - val_mae: 0.1208 - _timestamp: 1648559575.0000 - _runtime: 97.0000\n",
      "Epoch 45/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0264 - mae: 0.1165 - val_loss: 0.0275 - val_mae: 0.1192 - _timestamp: 1648559575.0000 - _runtime: 97.0000\n",
      "Epoch 46/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0257 - mae: 0.1153 - val_loss: 0.0272 - val_mae: 0.1183 - _timestamp: 1648559576.0000 - _runtime: 98.0000\n",
      "Epoch 47/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0250 - mae: 0.1135 - val_loss: 0.0263 - val_mae: 0.1168 - _timestamp: 1648559576.0000 - _runtime: 98.0000\n",
      "Epoch 48/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0245 - mae: 0.1125 - val_loss: 0.0257 - val_mae: 0.1152 - _timestamp: 1648559577.0000 - _runtime: 99.0000\n",
      "Epoch 49/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0241 - mae: 0.1115 - val_loss: 0.0255 - val_mae: 0.1147 - _timestamp: 1648559577.0000 - _runtime: 99.0000\n",
      "Epoch 50/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0235 - mae: 0.1099 - val_loss: 0.0250 - val_mae: 0.1134 - _timestamp: 1648559578.0000 - _runtime: 100.0000\n",
      "Epoch 51/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0230 - mae: 0.1089 - val_loss: 0.0246 - val_mae: 0.1124 - _timestamp: 1648559578.0000 - _runtime: 100.0000\n",
      "Epoch 52/200\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0226 - mae: 0.1075 - val_loss: 0.0239 - val_mae: 0.1107 - _timestamp: 1648559578.0000 - _runtime: 100.0000\n",
      "Epoch 53/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0220 - mae: 0.1063 - val_loss: 0.0231 - val_mae: 0.1089 - _timestamp: 1648559579.0000 - _runtime: 101.0000\n",
      "Epoch 54/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0216 - mae: 0.1051 - val_loss: 0.0229 - val_mae: 0.1082 - _timestamp: 1648559579.0000 - _runtime: 101.0000\n",
      "Epoch 55/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 0.1044 - val_loss: 0.0226 - val_mae: 0.1071 - _timestamp: 1648559579.0000 - _runtime: 101.0000\n",
      "Epoch 56/200\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 0.0208 - mae: 0.1029 - val_loss: 0.0218 - val_mae: 0.1050 - _timestamp: 1648559580.0000 - _runtime: 102.0000\n",
      "Epoch 57/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0202 - mae: 0.1016 - val_loss: 0.0221 - val_mae: 0.1062 - _timestamp: 1648559580.0000 - _runtime: 102.0000\n",
      "Epoch 58/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0199 - mae: 0.1005 - val_loss: 0.0209 - val_mae: 0.1028 - _timestamp: 1648559580.0000 - _runtime: 102.0000\n",
      "Epoch 59/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0195 - mae: 0.0994 - val_loss: 0.0209 - val_mae: 0.1034 - _timestamp: 1648559581.0000 - _runtime: 103.0000\n",
      "Epoch 60/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0190 - mae: 0.0980 - val_loss: 0.0203 - val_mae: 0.1008 - _timestamp: 1648559581.0000 - _runtime: 103.0000\n",
      "Epoch 61/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0186 - mae: 0.0971 - val_loss: 0.0198 - val_mae: 0.0994 - _timestamp: 1648559582.0000 - _runtime: 104.0000\n",
      "Epoch 62/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0182 - mae: 0.0958 - val_loss: 0.0196 - val_mae: 0.0989 - _timestamp: 1648559582.0000 - _runtime: 104.0000\n",
      "Epoch 63/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0181 - mae: 0.0952 - val_loss: 0.0195 - val_mae: 0.0986 - _timestamp: 1648559583.0000 - _runtime: 105.0000\n",
      "Epoch 64/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0176 - mae: 0.0937 - val_loss: 0.0190 - val_mae: 0.0976 - _timestamp: 1648559583.0000 - _runtime: 105.0000\n",
      "Epoch 65/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0928 - val_loss: 0.0189 - val_mae: 0.0966 - _timestamp: 1648559584.0000 - _runtime: 106.0000\n",
      "Epoch 66/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0169 - mae: 0.0917 - val_loss: 0.0185 - val_mae: 0.0946 - _timestamp: 1648559585.0000 - _runtime: 107.0000\n",
      "Epoch 67/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0167 - mae: 0.0908 - val_loss: 0.0179 - val_mae: 0.0941 - _timestamp: 1648559585.0000 - _runtime: 107.0000\n",
      "Epoch 68/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0164 - mae: 0.0900 - val_loss: 0.0179 - val_mae: 0.0941 - _timestamp: 1648559585.0000 - _runtime: 107.0000\n",
      "Epoch 69/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0162 - mae: 0.0894 - val_loss: 0.0172 - val_mae: 0.0915 - _timestamp: 1648559586.0000 - _runtime: 108.0000\n",
      "Epoch 70/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0157 - mae: 0.0879 - val_loss: 0.0170 - val_mae: 0.0909 - _timestamp: 1648559586.0000 - _runtime: 108.0000\n",
      "Epoch 71/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0155 - mae: 0.0870 - val_loss: 0.0169 - val_mae: 0.0905 - _timestamp: 1648559586.0000 - _runtime: 108.0000\n",
      "Epoch 72/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0154 - mae: 0.0866 - val_loss: 0.0164 - val_mae: 0.0892 - _timestamp: 1648559587.0000 - _runtime: 109.0000\n",
      "Epoch 73/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0150 - mae: 0.0855 - val_loss: 0.0165 - val_mae: 0.0885 - _timestamp: 1648559587.0000 - _runtime: 109.0000\n",
      "Epoch 74/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0149 - mae: 0.0849 - val_loss: 0.0161 - val_mae: 0.0877 - _timestamp: 1648559587.0000 - _runtime: 109.0000\n",
      "Epoch 75/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0146 - mae: 0.0841 - val_loss: 0.0159 - val_mae: 0.0867 - _timestamp: 1648559588.0000 - _runtime: 110.0000\n",
      "Epoch 76/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0144 - mae: 0.0835 - val_loss: 0.0155 - val_mae: 0.0861 - _timestamp: 1648559589.0000 - _runtime: 111.0000\n",
      "Epoch 77/200\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 0.0142 - mae: 0.0826 - val_loss: 0.0153 - val_mae: 0.0853 - _timestamp: 1648559589.0000 - _runtime: 111.0000\n",
      "Epoch 78/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0141 - mae: 0.0823 - val_loss: 0.0153 - val_mae: 0.0853 - _timestamp: 1648559590.0000 - _runtime: 112.0000\n",
      "Epoch 79/200\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0138 - mae: 0.0816 - val_loss: 0.0148 - val_mae: 0.0836 - _timestamp: 1648559590.0000 - _runtime: 112.0000\n",
      "Epoch 80/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0137 - mae: 0.0806 - val_loss: 0.0145 - val_mae: 0.0830 - _timestamp: 1648559591.0000 - _runtime: 113.0000\n",
      "Epoch 81/200\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.0134 - mae: 0.0799 - val_loss: 0.0150 - val_mae: 0.0834 - _timestamp: 1648559592.0000 - _runtime: 114.0000\n",
      "Epoch 82/200\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 0.0133 - mae: 0.0795 - val_loss: 0.0144 - val_mae: 0.0820 - _timestamp: 1648559593.0000 - _runtime: 115.0000\n",
      "Epoch 83/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0130 - mae: 0.0786 - val_loss: 0.0144 - val_mae: 0.0819 - _timestamp: 1648559593.0000 - _runtime: 115.0000\n",
      "Epoch 84/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0128 - mae: 0.0777 - val_loss: 0.0141 - val_mae: 0.0817 - _timestamp: 1648559594.0000 - _runtime: 116.0000\n",
      "Epoch 85/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0127 - mae: 0.0774 - val_loss: 0.0141 - val_mae: 0.0806 - _timestamp: 1648559594.0000 - _runtime: 116.0000\n",
      "Epoch 86/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0125 - mae: 0.0768 - val_loss: 0.0136 - val_mae: 0.0795 - _timestamp: 1648559595.0000 - _runtime: 117.0000\n",
      "Epoch 87/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0761 - val_loss: 0.0134 - val_mae: 0.0791 - _timestamp: 1648559595.0000 - _runtime: 117.0000\n",
      "Epoch 88/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0755 - val_loss: 0.0132 - val_mae: 0.0784 - _timestamp: 1648559596.0000 - _runtime: 118.0000\n",
      "Epoch 89/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0119 - mae: 0.0743 - val_loss: 0.0131 - val_mae: 0.0777 - _timestamp: 1648559596.0000 - _runtime: 118.0000\n",
      "Epoch 90/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0744 - val_loss: 0.0132 - val_mae: 0.0773 - _timestamp: 1648559597.0000 - _runtime: 119.0000\n",
      "Epoch 91/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0117 - mae: 0.0737 - val_loss: 0.0132 - val_mae: 0.0778 - _timestamp: 1648559597.0000 - _runtime: 119.0000\n",
      "Epoch 92/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0733 - val_loss: 0.0126 - val_mae: 0.0765 - _timestamp: 1648559598.0000 - _runtime: 120.0000\n",
      "Epoch 93/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0725 - val_loss: 0.0126 - val_mae: 0.0756 - _timestamp: 1648559598.0000 - _runtime: 120.0000\n",
      "Epoch 94/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0112 - mae: 0.0718 - val_loss: 0.0123 - val_mae: 0.0755 - _timestamp: 1648559599.0000 - _runtime: 121.0000\n",
      "Epoch 95/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.0718 - val_loss: 0.0124 - val_mae: 0.0757 - _timestamp: 1648559599.0000 - _runtime: 121.0000\n",
      "Epoch 96/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0111 - mae: 0.0720 - val_loss: 0.0120 - val_mae: 0.0737 - _timestamp: 1648559600.0000 - _runtime: 122.0000\n",
      "Epoch 97/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0108 - mae: 0.0710 - val_loss: 0.0118 - val_mae: 0.0736 - _timestamp: 1648559600.0000 - _runtime: 122.0000\n",
      "Epoch 98/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0707 - val_loss: 0.0122 - val_mae: 0.0743 - _timestamp: 1648559601.0000 - _runtime: 123.0000\n",
      "Epoch 99/200\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0108 - mae: 0.0704 - val_loss: 0.0116 - val_mae: 0.0725 - _timestamp: 1648559601.0000 - _runtime: 123.0000\n",
      "Epoch 100/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0104 - mae: 0.0693 - val_loss: 0.0119 - val_mae: 0.0739 - _timestamp: 1648559602.0000 - _runtime: 124.0000\n",
      "Epoch 101/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0104 - mae: 0.0691 - val_loss: 0.0115 - val_mae: 0.0722 - _timestamp: 1648559603.0000 - _runtime: 125.0000\n",
      "Epoch 102/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0102 - mae: 0.0688 - val_loss: 0.0113 - val_mae: 0.0715 - _timestamp: 1648559604.0000 - _runtime: 126.0000\n",
      "Epoch 103/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0680 - val_loss: 0.0110 - val_mae: 0.0705 - _timestamp: 1648559604.0000 - _runtime: 126.0000\n",
      "Epoch 104/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0100 - mae: 0.0680 - val_loss: 0.0112 - val_mae: 0.0711 - _timestamp: 1648559605.0000 - _runtime: 127.0000\n",
      "Epoch 105/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0100 - mae: 0.0678 - val_loss: 0.0110 - val_mae: 0.0711 - _timestamp: 1648559605.0000 - _runtime: 127.0000\n",
      "Epoch 106/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0099 - mae: 0.0676 - val_loss: 0.0110 - val_mae: 0.0704 - _timestamp: 1648559606.0000 - _runtime: 128.0000\n",
      "Epoch 107/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.0666 - val_loss: 0.0110 - val_mae: 0.0705 - _timestamp: 1648559606.0000 - _runtime: 128.0000\n",
      "Epoch 108/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0095 - mae: 0.0660 - val_loss: 0.0104 - val_mae: 0.0687 - _timestamp: 1648559607.0000 - _runtime: 129.0000\n",
      "Epoch 109/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0094 - mae: 0.0657 - val_loss: 0.0105 - val_mae: 0.0687 - _timestamp: 1648559608.0000 - _runtime: 130.0000\n",
      "Epoch 110/200\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 0.0094 - mae: 0.0654 - val_loss: 0.0110 - val_mae: 0.0699 - _timestamp: 1648559608.0000 - _runtime: 130.0000\n",
      "Epoch 111/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0093 - mae: 0.0652 - val_loss: 0.0102 - val_mae: 0.0675 - _timestamp: 1648559609.0000 - _runtime: 131.0000\n",
      "Epoch 112/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0092 - mae: 0.0644 - val_loss: 0.0104 - val_mae: 0.0679 - _timestamp: 1648559609.0000 - _runtime: 131.0000\n",
      "Epoch 113/200\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.0092 - mae: 0.0647 - val_loss: 0.0100 - val_mae: 0.0669 - _timestamp: 1648559610.0000 - _runtime: 132.0000\n",
      "Epoch 114/200\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0090 - mae: 0.0641 - val_loss: 0.0103 - val_mae: 0.0683 - _timestamp: 1648559611.0000 - _runtime: 133.0000\n",
      "Epoch 115/200\n",
      "55/55 [==============================] - 1s 21ms/step - loss: 0.0090 - mae: 0.0639 - val_loss: 0.0099 - val_mae: 0.0664 - _timestamp: 1648559612.0000 - _runtime: 134.0000\n",
      "Epoch 116/200\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0089 - mae: 0.0635 - val_loss: 0.0102 - val_mae: 0.0673 - _timestamp: 1648559613.0000 - _runtime: 135.0000\n",
      "Epoch 117/200\n",
      "55/55 [==============================] - 1s 22ms/step - loss: 0.0088 - mae: 0.0632 - val_loss: 0.0098 - val_mae: 0.0659 - _timestamp: 1648559614.0000 - _runtime: 136.0000\n",
      "Epoch 118/200\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0088 - mae: 0.0629 - val_loss: 0.0096 - val_mae: 0.0646 - _timestamp: 1648559615.0000 - _runtime: 137.0000\n",
      "Epoch 119/200\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 0.0085 - mae: 0.0619 - val_loss: 0.0094 - val_mae: 0.0644 - _timestamp: 1648559616.0000 - _runtime: 138.0000\n",
      "Epoch 120/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0085 - mae: 0.0618 - val_loss: 0.0098 - val_mae: 0.0658 - _timestamp: 1648559616.0000 - _runtime: 138.0000\n",
      "Epoch 121/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0085 - mae: 0.0617 - val_loss: 0.0094 - val_mae: 0.0645 - _timestamp: 1648559617.0000 - _runtime: 139.0000\n",
      "Epoch 122/200\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 0.0084 - mae: 0.0615 - val_loss: 0.0093 - val_mae: 0.0639 - _timestamp: 1648559618.0000 - _runtime: 140.0000\n",
      "Epoch 123/200\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0083 - mae: 0.0608 - val_loss: 0.0093 - val_mae: 0.0643 - _timestamp: 1648559619.0000 - _runtime: 141.0000\n",
      "Epoch 124/200\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.0082 - mae: 0.0607 - val_loss: 0.0093 - val_mae: 0.0637 - _timestamp: 1648559620.0000 - _runtime: 142.0000\n",
      "Epoch 125/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0083 - mae: 0.0610 - val_loss: 0.0093 - val_mae: 0.0639 - _timestamp: 1648559621.0000 - _runtime: 143.0000\n",
      "Epoch 126/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0082 - mae: 0.0606 - val_loss: 0.0092 - val_mae: 0.0633 - _timestamp: 1648559621.0000 - _runtime: 143.0000\n",
      "Epoch 127/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0082 - mae: 0.0602 - val_loss: 0.0091 - val_mae: 0.0628 - _timestamp: 1648559622.0000 - _runtime: 144.0000\n",
      "Epoch 128/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0081 - mae: 0.0601 - val_loss: 0.0090 - val_mae: 0.0624 - _timestamp: 1648559622.0000 - _runtime: 144.0000\n",
      "Epoch 129/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0080 - mae: 0.0595 - val_loss: 0.0089 - val_mae: 0.0622 - _timestamp: 1648559623.0000 - _runtime: 145.0000\n",
      "Epoch 130/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0079 - mae: 0.0593 - val_loss: 0.0089 - val_mae: 0.0619 - _timestamp: 1648559624.0000 - _runtime: 146.0000\n",
      "Epoch 131/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0080 - mae: 0.0594 - val_loss: 0.0092 - val_mae: 0.0629 - _timestamp: 1648559625.0000 - _runtime: 147.0000\n",
      "Epoch 132/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0079 - mae: 0.0594 - val_loss: 0.0090 - val_mae: 0.0620 - _timestamp: 1648559625.0000 - _runtime: 147.0000\n",
      "Epoch 133/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0079 - mae: 0.0590 - val_loss: 0.0087 - val_mae: 0.0610 - _timestamp: 1648559626.0000 - _runtime: 148.0000\n",
      "Epoch 134/200\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 0.0079 - mae: 0.0592 - val_loss: 0.0088 - val_mae: 0.0612 - _timestamp: 1648559627.0000 - _runtime: 149.0000\n",
      "Epoch 135/200\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 0.0077 - mae: 0.0581 - val_loss: 0.0088 - val_mae: 0.0611 - _timestamp: 1648559627.0000 - _runtime: 149.0000\n",
      "Epoch 136/200\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0077 - mae: 0.0582 - val_loss: 0.0086 - val_mae: 0.0609 - _timestamp: 1648559628.0000 - _runtime: 150.0000\n",
      "Epoch 137/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0076 - mae: 0.0578 - val_loss: 0.0087 - val_mae: 0.0614 - _timestamp: 1648559629.0000 - _runtime: 151.0000\n",
      "Epoch 138/200\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0077 - mae: 0.0583 - val_loss: 0.0085 - val_mae: 0.0605 - _timestamp: 1648559629.0000 - _runtime: 151.0000\n",
      "Epoch 139/200\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0075 - mae: 0.0574 - val_loss: 0.0086 - val_mae: 0.0605 - _timestamp: 1648559630.0000 - _runtime: 152.0000\n",
      "Epoch 140/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0075 - mae: 0.0574 - val_loss: 0.0084 - val_mae: 0.0596 - _timestamp: 1648559631.0000 - _runtime: 153.0000\n",
      "Epoch 141/200\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0569 - val_loss: 0.0087 - val_mae: 0.0612 - _timestamp: 1648559632.0000 - _runtime: 154.0000\n",
      "Epoch 142/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0075 - mae: 0.0572 - val_loss: 0.0088 - val_mae: 0.0617 - _timestamp: 1648559632.0000 - _runtime: 154.0000\n",
      "Epoch 143/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0074 - mae: 0.0574 - val_loss: 0.0083 - val_mae: 0.0590 - _timestamp: 1648559633.0000 - _runtime: 155.0000\n",
      "Epoch 144/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0074 - mae: 0.0564 - val_loss: 0.0084 - val_mae: 0.0598 - _timestamp: 1648559634.0000 - _runtime: 156.0000\n",
      "Epoch 145/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0568 - val_loss: 0.0084 - val_mae: 0.0602 - _timestamp: 1648559634.0000 - _runtime: 156.0000\n",
      "Epoch 146/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0075 - mae: 0.0576 - val_loss: 0.0080 - val_mae: 0.0585 - _timestamp: 1648559635.0000 - _runtime: 157.0000\n",
      "Epoch 147/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0560 - val_loss: 0.0083 - val_mae: 0.0593 - _timestamp: 1648559635.0000 - _runtime: 157.0000\n",
      "Epoch 148/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0564 - val_loss: 0.0082 - val_mae: 0.0590 - _timestamp: 1648559635.0000 - _runtime: 157.0000\n",
      "Epoch 149/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0564 - val_loss: 0.0081 - val_mae: 0.0588 - _timestamp: 1648559636.0000 - _runtime: 158.0000\n",
      "Epoch 150/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0559 - val_loss: 0.0081 - val_mae: 0.0587 - _timestamp: 1648559636.0000 - _runtime: 158.0000\n",
      "Epoch 151/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0559 - val_loss: 0.0082 - val_mae: 0.0590 - _timestamp: 1648559636.0000 - _runtime: 158.0000\n",
      "Epoch 152/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0561 - val_loss: 0.0080 - val_mae: 0.0586 - _timestamp: 1648559637.0000 - _runtime: 159.0000\n",
      "Epoch 153/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0551 - val_loss: 0.0081 - val_mae: 0.0586 - _timestamp: 1648559637.0000 - _runtime: 159.0000\n",
      "Epoch 154/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0070 - mae: 0.0551 - val_loss: 0.0081 - val_mae: 0.0587 - _timestamp: 1648559637.0000 - _runtime: 159.0000\n",
      "Epoch 155/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0072 - mae: 0.0557 - val_loss: 0.0083 - val_mae: 0.0592 - _timestamp: 1648559638.0000 - _runtime: 160.0000\n",
      "Epoch 156/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0553 - val_loss: 0.0078 - val_mae: 0.0576 - _timestamp: 1648559638.0000 - _runtime: 160.0000\n",
      "Epoch 157/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0070 - mae: 0.0553 - val_loss: 0.0079 - val_mae: 0.0585 - _timestamp: 1648559639.0000 - _runtime: 161.0000\n",
      "Epoch 158/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0070 - mae: 0.0547 - val_loss: 0.0082 - val_mae: 0.0594 - _timestamp: 1648559640.0000 - _runtime: 162.0000\n",
      "Epoch 159/200\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0069 - mae: 0.0547 - val_loss: 0.0081 - val_mae: 0.0589 - _timestamp: 1648559640.0000 - _runtime: 162.0000\n",
      "Epoch 160/200\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 0.0070 - mae: 0.0549 - val_loss: 0.0077 - val_mae: 0.0569 - _timestamp: 1648559641.0000 - _runtime: 163.0000\n",
      "Epoch 161/200\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 0.0068 - mae: 0.0541 - val_loss: 0.0078 - val_mae: 0.0575 - _timestamp: 1648559642.0000 - _runtime: 164.0000\n",
      "Epoch 162/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0069 - mae: 0.0545 - val_loss: 0.0078 - val_mae: 0.0572 - _timestamp: 1648559643.0000 - _runtime: 165.0000\n",
      "Epoch 163/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0547 - val_loss: 0.0078 - val_mae: 0.0575 - _timestamp: 1648559644.0000 - _runtime: 166.0000\n",
      "Epoch 164/200\n",
      "55/55 [==============================] - 1s 17ms/step - loss: 0.0068 - mae: 0.0543 - val_loss: 0.0077 - val_mae: 0.0572 - _timestamp: 1648559645.0000 - _runtime: 167.0000\n",
      "Epoch 165/200\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 0.0069 - mae: 0.0545 - val_loss: 0.0078 - val_mae: 0.0573 - _timestamp: 1648559645.0000 - _runtime: 167.0000\n",
      "Epoch 166/200\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 0.0068 - mae: 0.0537 - val_loss: 0.0075 - val_mae: 0.0557 - _timestamp: 1648559646.0000 - _runtime: 168.0000\n",
      "Epoch 167/200\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 0.0067 - mae: 0.0534 - val_loss: 0.0076 - val_mae: 0.0565 - _timestamp: 1648559647.0000 - _runtime: 169.0000\n",
      "Epoch 168/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0066 - mae: 0.0532 - val_loss: 0.0074 - val_mae: 0.0559 - _timestamp: 1648559647.0000 - _runtime: 169.0000\n",
      "Epoch 169/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0067 - mae: 0.0534 - val_loss: 0.0076 - val_mae: 0.0566 - _timestamp: 1648559648.0000 - _runtime: 170.0000\n",
      "Epoch 170/200\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0066 - mae: 0.0530 - val_loss: 0.0076 - val_mae: 0.0574 - _timestamp: 1648559649.0000 - _runtime: 171.0000\n",
      "Epoch 171/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0067 - mae: 0.0536 - val_loss: 0.0073 - val_mae: 0.0550 - _timestamp: 1648559649.0000 - _runtime: 171.0000\n",
      "Epoch 172/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0066 - mae: 0.0533 - val_loss: 0.0074 - val_mae: 0.0560 - _timestamp: 1648559650.0000 - _runtime: 172.0000\n",
      "Epoch 173/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0530 - val_loss: 0.0075 - val_mae: 0.0566 - _timestamp: 1648559650.0000 - _runtime: 172.0000\n",
      "Epoch 174/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0066 - mae: 0.0529 - val_loss: 0.0076 - val_mae: 0.0559 - _timestamp: 1648559651.0000 - _runtime: 173.0000\n",
      "Epoch 175/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0526 - val_loss: 0.0076 - val_mae: 0.0561 - _timestamp: 1648559651.0000 - _runtime: 173.0000\n",
      "Epoch 176/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0527 - val_loss: 0.0073 - val_mae: 0.0550 - _timestamp: 1648559651.0000 - _runtime: 173.0000\n",
      "Epoch 177/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0531 - val_loss: 0.0076 - val_mae: 0.0563 - _timestamp: 1648559652.0000 - _runtime: 174.0000\n",
      "Epoch 178/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0533 - val_loss: 0.0073 - val_mae: 0.0557 - _timestamp: 1648559652.0000 - _runtime: 174.0000\n",
      "Epoch 179/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0064 - mae: 0.0526 - val_loss: 0.0074 - val_mae: 0.0560 - _timestamp: 1648559653.0000 - _runtime: 175.0000\n",
      "Epoch 180/200\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 0.0066 - mae: 0.0529 - val_loss: 0.0072 - val_mae: 0.0549 - _timestamp: 1648559653.0000 - _runtime: 175.0000\n",
      "Epoch 181/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0065 - mae: 0.0524 - val_loss: 0.0074 - val_mae: 0.0560 - _timestamp: 1648559654.0000 - _runtime: 176.0000\n",
      "Epoch 182/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0520 - val_loss: 0.0074 - val_mae: 0.0554 - _timestamp: 1648559654.0000 - _runtime: 176.0000\n",
      "Epoch 183/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0520 - val_loss: 0.0072 - val_mae: 0.0552 - _timestamp: 1648559654.0000 - _runtime: 176.0000\n",
      "Epoch 184/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0516 - val_loss: 0.0071 - val_mae: 0.0546 - _timestamp: 1648559655.0000 - _runtime: 177.0000\n",
      "Epoch 185/200\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0063 - mae: 0.0517 - val_loss: 0.0072 - val_mae: 0.0545 - _timestamp: 1648559655.0000 - _runtime: 177.0000\n",
      "Epoch 186/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0515 - val_loss: 0.0073 - val_mae: 0.0551 - _timestamp: 1648559655.0000 - _runtime: 177.0000\n",
      "Epoch 187/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0523 - val_loss: 0.0072 - val_mae: 0.0556 - _timestamp: 1648559656.0000 - _runtime: 178.0000\n",
      "Epoch 188/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0517 - val_loss: 0.0072 - val_mae: 0.0552 - _timestamp: 1648559656.0000 - _runtime: 178.0000\n",
      "Epoch 189/200\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0515 - val_loss: 0.0074 - val_mae: 0.0556 - _timestamp: 1648559656.0000 - _runtime: 178.0000\n",
      "Epoch 190/200\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0521 - val_loss: 0.0071 - val_mae: 0.0548 - _timestamp: 1648559656.0000 - _runtime: 178.0000\n",
      "Epoch 191/200\n",
      "55/55 [==============================] - 1s 16ms/step - loss: 0.0062 - mae: 0.0513 - val_loss: 0.0070 - val_mae: 0.0539 - _timestamp: 1648559657.0000 - _runtime: 179.0000\n",
      "Epoch 192/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0062 - mae: 0.0510 - val_loss: 0.0069 - val_mae: 0.0533 - _timestamp: 1648559658.0000 - _runtime: 180.0000\n",
      "Epoch 193/200\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0062 - mae: 0.0511 - val_loss: 0.0071 - val_mae: 0.0541 - _timestamp: 1648559659.0000 - _runtime: 181.0000\n",
      "Epoch 194/200\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0506 - val_loss: 0.0071 - val_mae: 0.0543 - _timestamp: 1648559659.0000 - _runtime: 181.0000\n",
      "Epoch 195/200\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0062 - mae: 0.0510 - val_loss: 0.0070 - val_mae: 0.0538 - _timestamp: 1648559660.0000 - _runtime: 182.0000\n",
      "Epoch 196/200\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0504 - val_loss: 0.0069 - val_mae: 0.0532 - _timestamp: 1648559660.0000 - _runtime: 182.0000\n",
      "Epoch 197/200\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0061 - mae: 0.0511 - val_loss: 0.0069 - val_mae: 0.0537 - _timestamp: 1648559661.0000 - _runtime: 183.0000\n",
      "Epoch 198/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0060 - mae: 0.0503 - val_loss: 0.0072 - val_mae: 0.0549 - _timestamp: 1648559662.0000 - _runtime: 184.0000\n",
      "Epoch 199/200\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 0.0061 - mae: 0.0510 - val_loss: 0.0069 - val_mae: 0.0533 - _timestamp: 1648559662.0000 - _runtime: 184.0000\n",
      "Epoch 200/200\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0501 - val_loss: 0.0069 - val_mae: 0.0537 - _timestamp: 1648559663.0000 - _runtime: 185.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_scaled,\n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "    validation_data=(X_test_scaled,y_test_scaled),\n",
    "    callbacks=[WandbCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], label=\"Train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"MAE\")\n",
    "plt.plot(history.history[\"mae\"], label=\"Train\")\n",
    "plt.plot(history.history[\"val_mae\"], label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the model\n",
    "Compare ANN to Cheetah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"mu_x\": np.random.uniform(-1e-3, 1e-3),\n",
    "    \"mu_y\": np.random.uniform(-1e-3, 1e-3),\n",
    "    \"mu_xp\": np.random.uniform(-1e-4, 1e-4),\n",
    "    \"mu_yp\": np.random.uniform(-1e-4, 1e-4),\n",
    "    \"sigma_x\": np.random.uniform(1e-5, 5e-4),\n",
    "    \"sigma_y\": np.random.uniform(1e-5, 5e-4),\n",
    "    \"sigma_xp\": np.random.uniform(1e-6, 5e-5),\n",
    "    \"sigma_yp\": np.random.uniform(1e-6, 5e-5),\n",
    "    \"sigma_s\": np.random.uniform(1e-6, 5e-5),\n",
    "    \"sigma_p\": np.random.uniform(1e-4, 1e-3),\n",
    "    \"energy\": np.random.uniform(80e6, 160e6)\n",
    "}\n",
    "l = 0.2\n",
    "k1 = 13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterBeam(mu_x=-0.000444, mu_xp=0.001535, mu_y=-0.000813, mu_yp=-0.001862, sigma_x=0.000161, sigma_xp=0.000515, sigma_y=0.000590, sigma_yp=0.001323, sigma_s=0.000036, sigma_p=0.000414, energy=96388320.572)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoming = cheetah.ParameterBeam.from_parameters(**parameters)\n",
    "outgoing = cheetah.Quadrupole(length=l, k1=k1)(incoming)\n",
    "outgoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy = 95933520.0\n",
      "mu_x = -0.00037338511901907623\n",
      "mu_xp = 0.00180998130235821\n",
      "mu_y = -0.0008282114285975695\n",
      "mu_yp = -0.0018120380118489265\n",
      "sigma_p = 0.00041974845225922763\n",
      "sigma_s = 3.649721111287363e-05\n",
      "sigma_x = 0.00016954037710092962\n",
      "sigma_xp = 0.0004534504550974816\n",
      "sigma_y = 0.0005944134900346398\n",
      "sigma_yp = 0.0012517109280452132\n"
     ]
    }
   ],
   "source": [
    "X_try = np.array([[l, k1] + [parameters[k] for k in parameter_keys]])\n",
    "X_try_scaled = X_scaler.transform(X_try)\n",
    "\n",
    "y_try_scaled = model.predict(X_try_scaled)\n",
    "\n",
    "y_try = y_scaler.inverse_transform(y_try_scaled)\n",
    "outgoing = y_try.squeeze()\n",
    "\n",
    "for k, v in zip(parameter_keys, outgoing):\n",
    "    print(f\"{k} = {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05cbf078d01219c592fed14fc536999284c9d9d80b38ec1bed3cfe813d108552"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
